### Fetch
```cpp
 895 template <class Impl>
 896 void
 897 DefaultFetch<Impl>::tick()
 898 {
 899     list<ThreadID>::iterator threads = activeThreads->begin();
 900     list<ThreadID>::iterator end = activeThreads->end();
 901     bool status_change = false;
 902 
 903     wroteToTimeBuffer = false;
 904 
 905     for (ThreadID i = 0; i < numThreads; ++i) {
 906         issuePipelinedIfetch[i] = false;
 907     }
 908 
 909     while (threads != end) {
 910         ThreadID tid = *threads++;
 911 
 912         // Check the signals for each thread to determine the proper status
 913         // for each thread.
 914         bool updated_status = checkSignalsAndUpdate(tid);
 915         status_change =  status_change || updated_status;
 916     }
 917 
 918     DPRINTF(Fetch, "Running stage.\n");
 919 
 920     if (FullSystem) {
 921         if (fromCommit->commitInfo[0].interruptPending) {
 922             interruptPending = true;
 923         }
 924 
 925         if (fromCommit->commitInfo[0].clearInterrupt) {
 926             interruptPending = false;
 927         }
 928     }
 929 
 930     for (threadFetched = 0; threadFetched < numFetchingThreads;
 931          threadFetched++) {
 932         // Fetch each of the actively fetching threads.
 933         fetch(status_change);
 934     }
 935 
 936     // Record number of instructions fetched this cycle for distribution.
 937     fetchNisnDist.sample(numInst);
 938 
 939     if (status_change) {
 940         // Change the fetch stage status if there was a status change.
 941         _status = updateFetchStatus();
 942     }
 943 
 944     // Issue the next I-cache request if possible.
 945     for (ThreadID i = 0; i < numThreads; ++i) {
 946         if (issuePipelinedIfetch[i]) {
 947             pipelineIcacheAccesses(i);
 948         }
 949     }
 950 
 951     // Send instructions enqueued into the fetch queue to decode.
 952     // Limit rate by fetchWidth.  Stall if decode is stalled.
 953     unsigned insts_to_decode = 0;
 954     unsigned available_insts = 0;
 955 
 956     for (auto tid : *activeThreads) {
 957         if (!stalls[tid].decode) {
 958             available_insts += fetchQueue[tid].size();
 959         }
 960     }
 961 
 962     // Pick a random thread to start trying to grab instructions from
 963     auto tid_itr = activeThreads->begin();
 964     std::advance(tid_itr, random_mt.random<uint8_t>(0, activeThreads->size() - 1));
 965 
 966     while (available_insts != 0 && insts_to_decode < decodeWidth) {
 967         ThreadID tid = *tid_itr;
 968         if (!stalls[tid].decode && !fetchQueue[tid].empty()) {
 969             const auto& inst = fetchQueue[tid].front();
 970             toDecode->insts[toDecode->size++] = inst;
 971             DPRINTF(Fetch, "[tid:%i] [sn:%llu] Sending instruction to decode "
 972                     "from fetch queue. Fetch queue size: %i.\n",
 973                     tid, inst->seqNum, fetchQueue[tid].size());
 974 
 975             wroteToTimeBuffer = true;
 976             fetchQueue[tid].pop_front();
 977             insts_to_decode++;
 978             available_insts--;
 979         }
 980 
 981         tid_itr++;
 982         // Wrap around if at end of active threads list
 983         if (tid_itr == activeThreads->end())
 984             tid_itr = activeThreads->begin();
 985     }
 986 
 987     // If there was activity this cycle, inform the CPU of it.
 988     if (wroteToTimeBuffer) {
 989         DPRINTF(Activity, "Activity this cycle.\n");
 990         cpu->activityThisCycle();
 991     }
 992 
 993     // Reset the number of the instruction we've fetched.
 994     numInst = 0;
 995 }
```


## fetch: resolving TLB and cache accesses to actually fetches instructions
```cpp
1157 void
1158 DefaultFetch<Impl>::fetch(bool &status_change)
1159 {
1160     //////////////////////////////////////////
1161     // Start actual fetch
1162     //////////////////////////////////////////
1163     ThreadID tid = getFetchingThread();
1164 
1165     assert(!cpu->switchedOut());
1166 
1167     if (tid == InvalidThreadID) {
1168         // Breaks looping condition in tick()
1169         threadFetched = numFetchingThreads;
1170 
1171         if (numThreads == 1) {  // @todo Per-thread stats
1172             profileStall(0);
1173         }
1174 
1175         return;
1176     }
1177 
1178     DPRINTF(Fetch, "Attempting to fetch from [tid:%i]\n", tid);
1179 
1180     // The current PC.
1181     TheISA::PCState thisPC = pc[tid];
1182 
1183     Addr pcOffset = fetchOffset[tid];
1184     Addr fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1185 
1186     bool inRom = isRomMicroPC(thisPC.microPC());
1187 
1188     // If returning from the delay of a cache miss, then update the status
1189     // to running, otherwise do the cache access.  Possibly move this up
1190     // to tick() function.
1191     if (fetchStatus[tid] == IcacheAccessComplete) {
1192         DPRINTF(Fetch, "[tid:%i] Icache miss is complete.\n", tid);
1193 
1194         fetchStatus[tid] = Running;
1195         status_change = true;
1196     } else if (fetchStatus[tid] == Running) {
1197         // Align the fetch PC so its at the start of a fetch buffer segment.
1198         Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1199 
1200         // If buffer is no longer valid or fetchAddr has moved to point
1201         // to the next cache block, AND we have no remaining ucode
1202         // from a macro-op, then start fetch from icache.
1203         if (!(fetchBufferValid[tid] && fetchBufferBlockPC == fetchBufferPC[tid])
1204             && !inRom && !macroop[tid]) {
1205             DPRINTF(Fetch, "[tid:%i] Attempting to translate and read "
1206                     "instruction, starting at PC %s.\n", tid, thisPC);
1207 
1208             fetchCacheLine(fetchAddr, tid, thisPC.instAddr());
1209 
1210             if (fetchStatus[tid] == IcacheWaitResponse)
1211                 ++icacheStallCycles;
1212             else if (fetchStatus[tid] == ItlbWait)
1213                 ++fetchTlbCycles;
1214             else
1215                 ++fetchMiscStallCycles;
1216             return;
1217         } else if ((checkInterrupt(thisPC.instAddr()) && !delayedCommit[tid])) {
1218             // Stall CPU if an interrupt is posted and we're not issuing
1219             // an delayed commit micro-op currently (delayed commit instructions
1220             // are not interruptable by interrupts, only faults)
1221             ++fetchMiscStallCycles;
1222             DPRINTF(Fetch, "[tid:%i] Fetch is stalled!\n", tid);
1223             return;
1224         }
1225     } else {
1226         if (fetchStatus[tid] == Idle) {
1227             ++fetchIdleCycles;
1228             DPRINTF(Fetch, "[tid:%i] Fetch is idle!\n", tid);
1229         }
1230 
1231         // Status is Idle, so fetch should do nothing.
1232         return;
1233     }
1234 
1235     //when a requested instruction cache block is arrived(IcacheAccessComplete)
1236     ++fetchCycles;
1237 
1238     TheISA::PCState nextPC = thisPC;
1239 
1240     StaticInstPtr staticInst = NULL;
1241     StaticInstPtr curMacroop = macroop[tid];
1242 
1243     // If the read of the first instruction was successful, then grab the
1244     // instructions from the rest of the cache line and put them into the
1245     // queue heading to decode.
1246 
1247     DPRINTF(Fetch, "[tid:%i] Adding instructions to queue to "
1248             "decode.\n", tid);
1249 
1250     // Need to keep track of whether or not a predicted branch
1251     // ended this fetch block.
1252     bool predictedBranch = false;
1253 
1254     // Need to halt fetch if quiesce instruction detected
1255     bool quiesce = false;
1256 
1257     TheISA::MachInst *cacheInsts =
1258         reinterpret_cast<TheISA::MachInst *>(fetchBuffer[tid]);
1259 
1260     const unsigned numInsts = fetchBufferSize / instSize;
1261     unsigned blkOffset = (fetchAddr - fetchBufferPC[tid]) / instSize;
1262 
1263     // Loop through instruction memory from the cache.
1264     // Keep issuing while fetchWidth is available and branch is not
1265     // predicted taken
1266     while (numInst < fetchWidth && fetchQueue[tid].size() < fetchQueueSize
1267            && !predictedBranch && !quiesce) {
1268         // We need to process more memory if we aren't going to get a
1269         // StaticInst from the rom, the current macroop, or what's already
1270         // in the decoder.
1271         bool needMem = !inRom && !curMacroop &&
1272             !decoder[tid]->instReady();
1273         fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1274         Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1275 
1276         if (needMem) {
1277             // If buffer is no longer valid or fetchAddr has moved to point
1278             // to the next cache block then start fetch from icache.
1279             if (!fetchBufferValid[tid] ||
1280                 fetchBufferBlockPC != fetchBufferPC[tid])
1281                 break;
1282 
1283             if (blkOffset >= numInsts) {
1284                 // We need to process more memory, but we've run out of the
1285                 // current block.
1286                 break;
1287             }
1288 
1289             decoder[tid]->moreBytes(thisPC, fetchAddr, cacheInsts[blkOffset]);
1290 
1291             if (decoder[tid]->needMoreBytes()) {
1292                 blkOffset++;
1293                 fetchAddr += instSize;
1294                 pcOffset += instSize;
1295             }
1296         }
1297 
1298         // Extract as many instructions and/or microops as we can from
1299         // the memory we've processed so far.
1300         do {
1301             if (!(curMacroop || inRom)) {
1302                 if (decoder[tid]->instReady()) {
1303                     staticInst = decoder[tid]->decode(thisPC);
1304 
1305                     // Increment stat of fetched instructions.
1306                     ++fetchedInsts;
1307 
1308                     if (staticInst->isMacroop()) {
1309                         curMacroop = staticInst;
1310                     } else {
1311                         pcOffset = 0;
1312                     }
1313                 } else {
1314                     // We need more bytes for this instruction so blkOffset and
1315                     // pcOffset will be updated
1316                     break;
1317                 }
1318             }
1319             // Whether we're moving to a new macroop because we're at the
1320             // end of the current one, or the branch predictor incorrectly
1321             // thinks we are...
1322             bool newMacro = false;
1323             if (curMacroop || inRom) {
1324                 if (inRom) {
1325                     staticInst = cpu->microcodeRom.fetchMicroop(
1326                             thisPC.microPC(), curMacroop);
1327                 } else {
1328                     staticInst = curMacroop->fetchMicroop(thisPC.microPC());
1329                 }
1330                 newMacro |= staticInst->isLastMicroop();
1331             }
1332 
1333             DynInstPtr instruction =
1334                 buildInst(tid, staticInst, curMacroop,
1335                           thisPC, nextPC, true);
1336 
1337             ppFetch->notify(instruction);
1338             numInst++;
1339 
1340 #if TRACING_ON
1341             if (DTRACE(O3PipeView)) {
1342                 instruction->fetchTick = curTick();
1343             }
1344 #endif
1345 
1346             nextPC = thisPC;
1347 
1348             // If we're branching after this instruction, quit fetching
1349             // from the same block.
1350             predictedBranch |= thisPC.branching();
1351             predictedBranch |=
1352                 lookupAndUpdateNextPC(instruction, nextPC);
1353             if (predictedBranch) {
1354                 DPRINTF(Fetch, "Branch detected with PC = %s\n", thisPC);
1355             }
1356 
1357             newMacro |= thisPC.instAddr() != nextPC.instAddr();
1358 
1359             // Move to the next instruction, unless we have a branch.
1360             thisPC = nextPC;
1361             inRom = isRomMicroPC(thisPC.microPC());
1362 
1363             if (newMacro) {
1364                 fetchAddr = thisPC.instAddr() & BaseCPU::PCMask;
1365                 blkOffset = (fetchAddr - fetchBufferPC[tid]) / instSize;
1366                 pcOffset = 0;
1367                 curMacroop = NULL;
1368             }
1369 
1370             if (instruction->isQuiesce()) {
1371                 DPRINTF(Fetch,
1372                         "Quiesce instruction encountered, halting fetch!\n");
1373                 fetchStatus[tid] = QuiescePending;
1374                 status_change = true;
1375                 quiesce = true;
1376                 break;
1377             }
1378         } while ((curMacroop || decoder[tid]->instReady()) &&
1379                  numInst < fetchWidth &&
1380                  fetchQueue[tid].size() < fetchQueueSize);
1381 
1382         // Re-evaluate whether the next instruction to fetch is in micro-op ROM
1383         // or not.
1384         inRom = isRomMicroPC(thisPC.microPC());
1385     }
1386 
1387     if (predictedBranch) {
1388         DPRINTF(Fetch, "[tid:%i] Done fetching, predicted branch "
1389                 "instruction encountered.\n", tid);
1390     } else if (numInst >= fetchWidth) {
1391         DPRINTF(Fetch, "[tid:%i] Done fetching, reached fetch bandwidth "
1392                 "for this cycle.\n", tid);
1393     } else if (blkOffset >= fetchBufferSize) {
1394         DPRINTF(Fetch, "[tid:%i] Done fetching, reached the end of the"
1395                 "fetch buffer.\n", tid);
1396     }
1397 
1398     macroop[tid] = curMacroop;
1399     fetchOffset[tid] = pcOffset;
1400 
1401     if (numInst > 0) {
1402         wroteToTimeBuffer = true;
1403     }
1404 
1405     pc[tid] = thisPC;
1406 
1407     // pipeline a fetch if we're crossing a fetch buffer boundary and not in
1408     // a state that would preclude fetching
1409     fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1410     Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1411     issuePipelinedIfetch[tid] = fetchBufferBlockPC != fetchBufferPC[tid] &&
1412         fetchStatus[tid] != IcacheWaitResponse &&
1413         fetchStatus[tid] != ItlbWait &&
1414         fetchStatus[tid] != IcacheWaitRetry &&
1415         fetchStatus[tid] != QuiescePending &&
1416         !curMacroop;
1417 }
```
fetch function is pretty complex and long function to analyze at once. 
Therefore, we will take some part of the fetch function which are important to 
understand entire logic of the fetch stage of the O3 cpu. 


### getFetchingThread: selecting thread to let it fetch
If there are multiple threads need to fetch next instructions, 
the processor should select one among them to continue fetching. 
Based on the policy adopted by the processor, it can return 
different thread based on the current status of threads.

```cpp
1445 ///////////////////////////////////////
1446 //                                   //
1447 //  SMT FETCH POLICY MAINTAINED HERE //
1448 //                                   //
1449 ///////////////////////////////////////
1450 template<class Impl>
1451 ThreadID
1452 DefaultFetch<Impl>::getFetchingThread()
1453 {
1454     if (numThreads > 1) {
1455         switch (fetchPolicy) {
1456           case FetchPolicy::RoundRobin:
1457             return roundRobin();
1458           case FetchPolicy::IQCount:
1459             return iqCount();
1460           case FetchPolicy::LSQCount:
1461             return lsqCount();
1462           case FetchPolicy::Branch:
1463             return branchCount();
1464           default:
1465             return InvalidThreadID;
1466         }
1467     } else {
1468         list<ThreadID>::iterator thread = activeThreads->begin();
1469         if (thread == activeThreads->end()) {
1470             return InvalidThreadID;
1471         }
1472 
1473         ThreadID tid = *thread;
1474 
1475         if (fetchStatus[tid] == Running ||
1476             fetchStatus[tid] == IcacheAccessComplete ||
1477             fetchStatus[tid] == Idle) {
1478             return tid;
1479         } else {
1480             return InvalidThreadID;
1481         }
1482     }
1483 }

```



### Translating virtual to physical address using I-TLB

```cpp
 602 template <class Impl>
 603 bool
 604 DefaultFetch<Impl>::fetchCacheLine(Addr vaddr, ThreadID tid, Addr pc)
 605 {   
 606     Fault fault = NoFault;
 607     
 608     assert(!cpu->switchedOut());
 609     
 610     // @todo: not sure if these should block translation.
 611     //AlphaDep
 612     if (cacheBlocked) {
 613         DPRINTF(Fetch, "[tid:%i] Can't fetch cache line, cache blocked\n",
 614                 tid);
 615         return false;
 616     } else if (checkInterrupt(pc) && !delayedCommit[tid]) {
 617         // Hold off fetch from getting new instructions when:
 618         // Cache is blocked, or
 619         // while an interrupt is pending and we're not in PAL mode, or
 620         // fetch is switched out.
 621         DPRINTF(Fetch, "[tid:%i] Can't fetch cache line, interrupt pending\n",
 622                 tid);
 623         return false;
 624     }
 625     
 626     // Align the fetch address to the start of a fetch buffer segment.
 627     Addr fetchBufferBlockPC = fetchBufferAlignPC(vaddr);
 628     
 629     DPRINTF(Fetch, "[tid:%i] Fetching cache line %#x for addr %#x\n",
 630             tid, fetchBufferBlockPC, vaddr);
 631     
 632     // Setup the memReq to do a read of the first instruction's address.
 633     // Set the appropriate read size and flags as well.
 634     // Build request here.
 635     RequestPtr mem_req = std::make_shared<Request>(
 636         tid, fetchBufferBlockPC, fetchBufferSize, 
 637         Request::INST_FETCH, cpu->instMasterId(), pc,
 638         cpu->thread[tid]->contextId());
 639     
 640     mem_req->taskId(cpu->taskId());
 641     
 642     memReq[tid] = mem_req;
 643     
 644     // Initiate translation of the icache block
 645     fetchStatus[tid] = ItlbWait;
 646     FetchTranslation *trans = new FetchTranslation(this);
 647     cpu->itb->translateTiming(mem_req, cpu->thread[tid]->getTC(),
 648                               trans, BaseTLB::Execute);
 649     return true;
 650 }
```

```cpp
115     class FetchTranslation : public BaseTLB::Translation
116     {
117       protected:
118         DefaultFetch<Impl> *fetch;
119 
120       public:
121         FetchTranslation(DefaultFetch<Impl> *_fetch)
122             : fetch(_fetch)
123         {}
124 
125         void
126         markDelayed()
127         {}
128 
129         void
130         finish(const Fault &fault, const RequestPtr &req, ThreadContext *tc,
131                BaseTLB::Mode mode)
132         {
133             assert(mode == BaseTLB::Execute);
134             fetch->finishTranslation(fault, req);
135             delete this;
136         }
137     };

u
ㅕu


OBOAOA
:w
:
:W
:w
[O[I[O[I[O
```

### Finishing TLB access and generate cache access
```cpp
 652 template <class Impl>
 653 void
 654 DefaultFetch<Impl>::finishTranslation(const Fault &fault,
 655                                       const RequestPtr &mem_req)
 656 {
 657     ThreadID tid = cpu->contextToThread(mem_req->contextId());
 658     Addr fetchBufferBlockPC = mem_req->getVaddr();
 659 
 660     assert(!cpu->switchedOut());
 661 
 662     // Wake up CPU if it was idle
 663     cpu->wakeCPU();
 664 
 665     if (fetchStatus[tid] != ItlbWait || mem_req != memReq[tid] ||
 666         mem_req->getVaddr() != memReq[tid]->getVaddr()) {
 667         DPRINTF(Fetch, "[tid:%i] Ignoring itlb completed after squash... fetchStatus:%d\n",
 668                 tid,fetchStatus[tid]);
 669         ++fetchTlbSquashes;
 670         return;
 671     }
 672 
 673 
 674     // If translation was successful, attempt to read the icache block.
 675     if (fault == NoFault) {
 676         // Check that we're not going off into random memory
 677         // If we have, just wait around for commit to squash something and put
 678         // us on the right track
 679         if (!cpu->system->isMemAddr(mem_req->getPaddr())) {
 680             warn("Address %#x is outside of physical memory, stopping fetch\n",
 681                     mem_req->getPaddr());
 682             fetchStatus[tid] = NoGoodAddr;
 683             memReq[tid] = NULL;
 684             return;
 685         }
 686 
 687         // Build packet here to access the Icache.
 688         PacketPtr data_pkt = new Packet(mem_req, MemCmd::ReadReq);
 689         data_pkt->dataDynamic(new uint8_t[fetchBufferSize]);
 690 
 691         fetchBufferPC[tid] = fetchBufferBlockPC;
 692         fetchBufferValid[tid] = false;
 693         DPRINTF(Fetch, "Fetch: Doing instruction read.\n");
 694 
 695         fetchedCacheLines++;
 696 
 697         // Access the cache.
 698         if (!icachePort.sendTimingReq(data_pkt)) {
 699             assert(retryPkt == NULL);
 700             assert(retryTid == InvalidThreadID);
 701             DPRINTF(Fetch, "[tid:%i] Out of MSHRs!\n", tid);
 702 
 703             fetchStatus[tid] = IcacheWaitRetry;
 704             retryPkt = data_pkt;
 705             retryTid = tid;
 706             cacheBlocked = true;
 707         } else {
 708             DPRINTF(Fetch, "[tid:%i] Doing Icache access.\n", tid);
 709             DPRINTF(Activity, "[tid:%i] Activity: Waiting on I-cache "
 710                     "response.\n", tid);
 711             lastIcacheStall[tid] = curTick();
 712             fetchStatus[tid] = IcacheWaitResponse;
 713             // Notify Fetch Request probe when a packet containing a fetch
 714             // request is successfully sent
 715             ppFetchRequestSent->notify(mem_req);
 716         }
 717     } else {
 718         // Don't send an instruction to decode if we can't handle it.
 719         if (!(numInst < fetchWidth) || !(fetchQueue[tid].size() < fetchQueueSize)) {
 720             assert(!finishTranslationEvent.scheduled());
 721             finishTranslationEvent.setFault(fault);
 722             finishTranslationEvent.setReq(mem_req);
 723             cpu->schedule(finishTranslationEvent,
 724                           cpu->clockEdge(Cycles(1)));
 725             return;
 726         }
 727         DPRINTF(Fetch, "[tid:%i] Got back req with addr %#x but expected %#x\n",
 728                 tid, mem_req->getVaddr(), memReq[tid]->getVaddr());
 729         // Translation faulted, icache request won't be sent.
 730         memReq[tid] = NULL;
 731 
 732         // Send the fault to commit.  This thread will not do anything
 733         // until commit handles the fault.  The only other way it can
 734         // wake up is if a squash comes along and changes the PC.
 735         TheISA::PCState fetchPC = pc[tid];
 736 
 737         DPRINTF(Fetch, "[tid:%i] Translation faulted, building noop.\n", tid);
 738         // We will use a nop in ordier to carry the fault.
 739         DynInstPtr instruction = buildInst(tid, StaticInst::nopStaticInstPtr,
 740                                            NULL, fetchPC, fetchPC, false);
 741         instruction->setNotAnInst();
 742 
 743         instruction->setPredTarg(fetchPC);
 744         instruction->fault = fault;
 745         wroteToTimeBuffer = true;
 746 
 747         DPRINTF(Activity, "Activity this cycle.\n");
 748         cpu->activityThisCycle();
 749 
 750         fetchStatus[tid] = TrapPending;
 751 
 752         DPRINTF(Fetch, "[tid:%i] Blocked, need to handle the trap.\n", tid);
 753         DPRINTF(Fetch, "[tid:%i] fault (%s) detected @ PC %s.\n",
 754                 tid, fault->name(), pc[tid]);
 755     }
 756     _status = updateFetchStatus();
 757 }



```








### processCacheCompletion: completing ICache access 

```cpp
1676 template<class Impl>
1677 bool
1678 DefaultFetch<Impl>::IcachePort::recvTimingResp(PacketPtr pkt)
1679 {
1680     DPRINTF(O3CPU, "Fetch unit received timing\n");
1681     // We shouldn't ever get a cacheable block in Modified state
1682     assert(pkt->req->isUncacheable() ||
1683            !(pkt->cacheResponding() && !pkt->hasSharers()));
1684     fetch->processCacheCompletion(pkt);
1685 
1686     return true;
1687 }
```


```cpp
 389 DefaultFetch<Impl>::processCacheCompletion(PacketPtr pkt)
 390 {
 391     ThreadID tid = cpu->contextToThread(pkt->req->contextId());
 392 
 393     DPRINTF(Fetch, "[tid:%i] Waking up from cache miss.\n", tid);
 394     assert(!cpu->switchedOut());
 395 
 396     // Only change the status if it's still waiting on the icache access
 397     // to return.
 398     if (fetchStatus[tid] != IcacheWaitResponse ||
 399         pkt->req != memReq[tid]) {
 400         ++fetchIcacheSquashes;
 401         delete pkt;
 402         return;
 403     }
 404 
 405     memcpy(fetchBuffer[tid], pkt->getConstPtr<uint8_t>(), fetchBufferSize);
 406     fetchBufferValid[tid] = true;
 407 
 408     // Wake up the CPU (if it went to sleep and was waiting on
 409     // this completion event).
 410     cpu->wakeCPU();
 411 
 412     DPRINTF(Activity, "[tid:%i] Activating fetch due to cache completion\n",
 413             tid);
 414 
 415     switchToActive();
 416 
 417     // Only switch to IcacheAccessComplete if we're not stalled as well.
 418     if (checkStall(tid)) {
 419         fetchStatus[tid] = Blocked;
 420     } else {
 421         fetchStatus[tid] = IcacheAccessComplete;
 422     }
 423 
 424     pkt->req->setAccessLatency();
 425     cpu->ppInstAccessComplete->notify(pkt);
 426     // Reset the mem req to NULL.
 427     delete pkt;
 428     memReq[tid] = NULL;
 429 }

```

