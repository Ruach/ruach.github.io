### Fetch
```cpp
 895 template <class Impl>
 896 void
 897 DefaultFetch<Impl>::tick()
 898 {
 899     list<ThreadID>::iterator threads = activeThreads->begin();
 900     list<ThreadID>::iterator end = activeThreads->end();
 901     bool status_change = false;
 902 
 903     wroteToTimeBuffer = false;
 904 
 905     for (ThreadID i = 0; i < numThreads; ++i) {
 906         issuePipelinedIfetch[i] = false;
 907     }
 908 
 909     while (threads != end) {
 910         ThreadID tid = *threads++;
 911 
 912         // Check the signals for each thread to determine the proper status
 913         // for each thread.
 914         bool updated_status = checkSignalsAndUpdate(tid);
 915         status_change =  status_change || updated_status;
 916     }
 917 
 918     DPRINTF(Fetch, "Running stage.\n");
 919 
 920     if (FullSystem) {
 921         if (fromCommit->commitInfo[0].interruptPending) {
 922             interruptPending = true;
 923         }
 924 
 925         if (fromCommit->commitInfo[0].clearInterrupt) {
 926             interruptPending = false;
 927         }
 928     }
 929 
 930     for (threadFetched = 0; threadFetched < numFetchingThreads;
 931          threadFetched++) {
 932         // Fetch each of the actively fetching threads.
 933         fetch(status_change);
 934     }
 935 
 936     // Record number of instructions fetched this cycle for distribution.
 937     fetchNisnDist.sample(numInst);
 938 
 939     if (status_change) {
 940         // Change the fetch stage status if there was a status change.
 941         _status = updateFetchStatus();
 942     }
 943 
 944     // Issue the next I-cache request if possible.
 945     for (ThreadID i = 0; i < numThreads; ++i) {
 946         if (issuePipelinedIfetch[i]) {
 947             pipelineIcacheAccesses(i);
 948         }
 949     }
 950 
 951     // Send instructions enqueued into the fetch queue to decode.
 952     // Limit rate by fetchWidth.  Stall if decode is stalled.
 953     unsigned insts_to_decode = 0;
 954     unsigned available_insts = 0;
 955 
 956     for (auto tid : *activeThreads) {
 957         if (!stalls[tid].decode) {
 958             available_insts += fetchQueue[tid].size();
 959         }
 960     }
 961 
 962     // Pick a random thread to start trying to grab instructions from
 963     auto tid_itr = activeThreads->begin();
 964     std::advance(tid_itr, random_mt.random<uint8_t>(0, activeThreads->size() - 1));
 965 
 966     while (available_insts != 0 && insts_to_decode < decodeWidth) {
 967         ThreadID tid = *tid_itr;
 968         if (!stalls[tid].decode && !fetchQueue[tid].empty()) {
 969             const auto& inst = fetchQueue[tid].front();
 970             toDecode->insts[toDecode->size++] = inst;
 971             DPRINTF(Fetch, "[tid:%i] [sn:%llu] Sending instruction to decode "
 972                     "from fetch queue. Fetch queue size: %i.\n",
 973                     tid, inst->seqNum, fetchQueue[tid].size());
 974 
 975             wroteToTimeBuffer = true;
 976             fetchQueue[tid].pop_front();
 977             insts_to_decode++;
 978             available_insts--;
 979         }
 980 
 981         tid_itr++;
 982         // Wrap around if at end of active threads list
 983         if (tid_itr == activeThreads->end())
 984             tid_itr = activeThreads->begin();
 985     }
 986 
 987     // If there was activity this cycle, inform the CPU of it.
 988     if (wroteToTimeBuffer) {
 989         DPRINTF(Activity, "Activity this cycle.\n");
 990         cpu->activityThisCycle();
 991     }
 992 
 993     // Reset the number of the instruction we've fetched.
 994     numInst = 0;
 995 }
```


## fetch: resolving TLB and cache accesses to actually fetches instructions
```cpp
1157 void
1158 DefaultFetch<Impl>::fetch(bool &status_change)
1159 {
1160     //////////////////////////////////////////
1161     // Start actual fetch
1162     //////////////////////////////////////////
1163     ThreadID tid = getFetchingThread();
1164 
1165     assert(!cpu->switchedOut());
1166 
1167     if (tid == InvalidThreadID) {
1168         // Breaks looping condition in tick()
1169         threadFetched = numFetchingThreads;
1170 
1171         if (numThreads == 1) {  // @todo Per-thread stats
1172             profileStall(0);
1173         }
1174 
1175         return;
1176     }
1177 
1178     DPRINTF(Fetch, "Attempting to fetch from [tid:%i]\n", tid);
1179 
1180     // The current PC.
1181     TheISA::PCState thisPC = pc[tid];
1182 
1183     Addr pcOffset = fetchOffset[tid];
1184     Addr fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1185 
1186     bool inRom = isRomMicroPC(thisPC.microPC());
1187 
1188     // If returning from the delay of a cache miss, then update the status
1189     // to running, otherwise do the cache access.  Possibly move this up
1190     // to tick() function.
1191     if (fetchStatus[tid] == IcacheAccessComplete) {
1192         DPRINTF(Fetch, "[tid:%i] Icache miss is complete.\n", tid);
1193 
1194         fetchStatus[tid] = Running;
1195         status_change = true;
1196     } else if (fetchStatus[tid] == Running) {
1197         // Align the fetch PC so its at the start of a fetch buffer segment.
1198         Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1199 
1200         // If buffer is no longer valid or fetchAddr has moved to point
1201         // to the next cache block, AND we have no remaining ucode
1202         // from a macro-op, then start fetch from icache.
1203         if (!(fetchBufferValid[tid] && fetchBufferBlockPC == fetchBufferPC[tid])
1204             && !inRom && !macroop[tid]) {
1205             DPRINTF(Fetch, "[tid:%i] Attempting to translate and read "
1206                     "instruction, starting at PC %s.\n", tid, thisPC);
1207 
1208             fetchCacheLine(fetchAddr, tid, thisPC.instAddr());
1209 
1210             if (fetchStatus[tid] == IcacheWaitResponse)
1211                 ++icacheStallCycles;
1212             else if (fetchStatus[tid] == ItlbWait)
1213                 ++fetchTlbCycles;
1214             else
1215                 ++fetchMiscStallCycles;
1216             return;
1217         } else if ((checkInterrupt(thisPC.instAddr()) && !delayedCommit[tid])) {
1218             // Stall CPU if an interrupt is posted and we're not issuing
1219             // an delayed commit micro-op currently (delayed commit instructions
1220             // are not interruptable by interrupts, only faults)
1221             ++fetchMiscStallCycles;
1222             DPRINTF(Fetch, "[tid:%i] Fetch is stalled!\n", tid);
1223             return;
1224         }
1225     } else {
1226         if (fetchStatus[tid] == Idle) {
1227             ++fetchIdleCycles;
1228             DPRINTF(Fetch, "[tid:%i] Fetch is idle!\n", tid);
1229         }
1230 
1231         // Status is Idle, so fetch should do nothing.
1232         return;
1233     }
......
1417 }

```
The fetch function is pretty complex and long function to analyze at once. 
Therefore, we will divide the fetch function in two main parts to understand
entire logic of the O3CPU's fetch stage. The first main part will explain 
how the fetch stage generate request to ITLB and ICache to resolve virtual to 
physical address translation and access the cache using the translated address. 
After the fetch stage receive the instructions from the ICache, the remaining part
will prepare the data structure that will be passed to the next stage, decode. 
Let's take a look at how the fetch function retrieve the instructions first.


## First part of the fetch: ITLB to ICache access. 

### getFetchingThread: selecting thread to let it fetch
If there are multiple threads need to fetch next instructions, 
the processor should select one among them to continue fetching. 
Based on the policy adopted by the processor, it can return 
different thread based on the current status of threads.

```cpp
1445 ///////////////////////////////////////
1446 //                                   //
1447 //  SMT FETCH POLICY MAINTAINED HERE //
1448 //                                   //
1449 ///////////////////////////////////////
1450 template<class Impl>
1451 ThreadID
1452 DefaultFetch<Impl>::getFetchingThread()
1453 {
1454     if (numThreads > 1) {
1455         switch (fetchPolicy) {
1456           case FetchPolicy::RoundRobin:
1457             return roundRobin();
1458           case FetchPolicy::IQCount:
1459             return iqCount();
1460           case FetchPolicy::LSQCount:
1461             return lsqCount();
1462           case FetchPolicy::Branch:
1463             return branchCount();
1464           default:
1465             return InvalidThreadID;
1466         }
1467     } else {
1468         list<ThreadID>::iterator thread = activeThreads->begin();
1469         if (thread == activeThreads->end()) {
1470             return InvalidThreadID;
1471         }
1472 
1473         ThreadID tid = *thread;
1474 
1475         if (fetchStatus[tid] == Running ||
1476             fetchStatus[tid] == IcacheAccessComplete ||
1477             fetchStatus[tid] == Idle) {
1478             return tid;
1479         } else {
1480             return InvalidThreadID;
1481         }
1482     }
1483 }

```



### Translating virtual to physical address using I-TLB

```cpp
 602 template <class Impl>
 603 bool
 604 DefaultFetch<Impl>::fetchCacheLine(Addr vaddr, ThreadID tid, Addr pc)
 605 {   
 606     Fault fault = NoFault;
 607     
 608     assert(!cpu->switchedOut());
 609     
 610     // @todo: not sure if these should block translation.
 611     //AlphaDep
 612     if (cacheBlocked) {
 613         DPRINTF(Fetch, "[tid:%i] Can't fetch cache line, cache blocked\n",
 614                 tid);
 615         return false;
 616     } else if (checkInterrupt(pc) && !delayedCommit[tid]) {
 617         // Hold off fetch from getting new instructions when:
 618         // Cache is blocked, or
 619         // while an interrupt is pending and we're not in PAL mode, or
 620         // fetch is switched out.
 621         DPRINTF(Fetch, "[tid:%i] Can't fetch cache line, interrupt pending\n",
 622                 tid);
 623         return false;
 624     }
 625     
 626     // Align the fetch address to the start of a fetch buffer segment.
 627     Addr fetchBufferBlockPC = fetchBufferAlignPC(vaddr);
 628     
 629     DPRINTF(Fetch, "[tid:%i] Fetching cache line %#x for addr %#x\n",
 630             tid, fetchBufferBlockPC, vaddr);
 631     
 632     // Setup the memReq to do a read of the first instruction's address.
 633     // Set the appropriate read size and flags as well.
 634     // Build request here.
 635     RequestPtr mem_req = std::make_shared<Request>(
 636         tid, fetchBufferBlockPC, fetchBufferSize, 
 637         Request::INST_FETCH, cpu->instMasterId(), pc,
 638         cpu->thread[tid]->contextId());
 639     
 640     mem_req->taskId(cpu->taskId());
 641     
 642     memReq[tid] = mem_req;
 643     
 644     // Initiate translation of the icache block
 645     fetchStatus[tid] = ItlbWait;
 646     FetchTranslation *trans = new FetchTranslation(this);
 647     cpu->itb->translateTiming(mem_req, cpu->thread[tid]->getTC(),
 648                               trans, BaseTLB::Execute);
 649     return true;
 650 }
```

One can ask how the fetch stage can understand when the translation is finished.
Note that **FetchTranslation** object is instantiated and sent to the 
Instruction TLB (itb) which conveys functions that should be invoked 
after the Translation is resolved. Therefore, when the instruction TLB finishes
the translation, it invokes the function provided by the passed FetchTranslation object and 
let the fetch stage to process next step, accessing the cache. 
Anyway, let's take a look at which function is provided to the TLB.

*gem5/src/cpu/o3/fetch.hh*
```cpp
115     class FetchTranslation : public BaseTLB::Translation
116     {
117       protected:
118         DefaultFetch<Impl> *fetch;
119 
120       public:
121         FetchTranslation(DefaultFetch<Impl> *_fetch)
122             : fetch(_fetch)
123         {}
124 
125         void
126         markDelayed()
127         {}
128 
129         void
130         finish(const Fault &fault, const RequestPtr &req, ThreadContext *tc,
131                BaseTLB::Mode mode)
132         {
133             assert(mode == BaseTLB::Execute);
134             fetch->finishTranslation(fault, req);
135             delete this;
136         }
137     };
```

You might remember that the TLB invokes the **finish** function at the end of the translation
Yes the FetchTranslation object provide the finish function. When the TLB finishes translation,
by invoking finish function, it can let the processor know the translation is resolved. 
The finish function further invokes the **finishTranslation** function defined in the 
DefaultFetch class. 

### finishTranslation: finishing TLB access and generate cache access
After the request to the TLB has been resolved, the remaining job is accessing the cache 
to read the instruction to fetch. Let's take a look at how the fetch stage of the O3 CPU 
access the instruction cache.

```cpp
 652 template <class Impl>
 653 void
 654 DefaultFetch<Impl>::finishTranslation(const Fault &fault,
 655                                       const RequestPtr &mem_req)
 656 {
 657     ThreadID tid = cpu->contextToThread(mem_req->contextId());
 658     Addr fetchBufferBlockPC = mem_req->getVaddr();
 659 
 660     assert(!cpu->switchedOut());
 661 
 662     // Wake up CPU if it was idle
 663     cpu->wakeCPU();
 664 
 665     if (fetchStatus[tid] != ItlbWait || mem_req != memReq[tid] ||
 666         mem_req->getVaddr() != memReq[tid]->getVaddr()) {
 667         DPRINTF(Fetch, "[tid:%i] Ignoring itlb completed after squash... fetchStatus:%d\n",
 668                 tid,fetchStatus[tid]);
 669         ++fetchTlbSquashes;
 670         return;
 671     }
```
Compared to simple processor which doesn't provide speculative execution, 
O3 processor utilize the branch prediction and out-of-order execution. 
Therefore, if the current TLB completion is notified to the O3CPU because of a
misspeculation, it should drop the TLB response and stop accessing the cache.
Note that the speculation can turn out to be false while it waits TLB response.
Line 665-670 checks the misspeculation. 

```cpp
 674     // If translation was successful, attempt to read the icache block.
 675     if (fault == NoFault) {
 676         // Check that we're not going off into random memory
 677         // If we have, just wait around for commit to squash something and put
 678         // us on the right track
 679         if (!cpu->system->isMemAddr(mem_req->getPaddr())) {
 680             warn("Address %#x is outside of physical memory, stopping fetch\n",
 681                     mem_req->getPaddr());
 682             fetchStatus[tid] = NoGoodAddr;
 683             memReq[tid] = NULL;
 684             return;
 685         }
 686 
 687         // Build packet here to access the Icache.
 688         PacketPtr data_pkt = new Packet(mem_req, MemCmd::ReadReq);
 689         data_pkt->dataDynamic(new uint8_t[fetchBufferSize]);
 690 
 691         fetchBufferPC[tid] = fetchBufferBlockPC;
 692         fetchBufferValid[tid] = false;
 693         DPRINTF(Fetch, "Fetch: Doing instruction read.\n");
 694 
 695         fetchedCacheLines++;
 696
 697         // Access the cache.
 698         if (!icachePort.sendTimingReq(data_pkt)) {
 699             assert(retryPkt == NULL);
 700             assert(retryTid == InvalidThreadID);
 701             DPRINTF(Fetch, "[tid:%i] Out of MSHRs!\n", tid);
 702 
 703             fetchStatus[tid] = IcacheWaitRetry;
 704             retryPkt = data_pkt;
 705             retryTid = tid;
 706             cacheBlocked = true;
 707         } else {
 708             DPRINTF(Fetch, "[tid:%i] Doing Icache access.\n", tid);
 709             DPRINTF(Activity, "[tid:%i] Activity: Waiting on I-cache "
 710                     "response.\n", tid);
 711             lastIcacheStall[tid] = curTick();
 712             fetchStatus[tid] = IcacheWaitResponse;
 713             // Notify Fetch Request probe when a packet containing a fetch
 714             // request is successfully sent
 715             ppFetchRequestSent->notify(mem_req);
 716         }
 717     } else {
```
If the current TLB resolution response is valid and speculated successfully, 
it should generate read request packet and send it to the Instruction Cache. 
Line 687-695 builds the packet and send buffer to be used for containing 
instructions read from the cache. 
When the cache access request cannot be sent to the instruction cache (line 698-707)
because of the cache is busy for handling previous requests,
it should retry when the Instruction cache is available later. 
Based on the line 701, we can guess that the cache supports multiple cache accesses simultaneously,
but the request can exceed the capacity of its simultaneous processing.
We will see whether the GEM5 supports blocking cache access or non-blocking cache accesses in another posting.
Anyway when the retry is required, it memorizes the request packet and tid. 
Also it changes current status as **IcacheWaitRetry**.
When the Instruction cache is available to process the request (line 708-716), 
it sets current status as  **IcacheWaitResponse** and waits 
until the Instruction cache resolves the request and send the actual instructions. 


```cpp
 717     } else {
 718         // Don't send an instruction to decode if we can't handle it.
 719         if (!(numInst < fetchWidth) || !(fetchQueue[tid].size() < fetchQueueSize)) {
 720             assert(!finishTranslationEvent.scheduled());
 721             finishTranslationEvent.setFault(fault);
 722             finishTranslationEvent.setReq(mem_req);
 723             cpu->schedule(finishTranslationEvent,
 724                           cpu->clockEdge(Cycles(1)));
 725             return;
 726         }
 727         DPRINTF(Fetch, "[tid:%i] Got back req with addr %#x but expected %#x\n",
 728                 tid, mem_req->getVaddr(), memReq[tid]->getVaddr());
 729         // Translation faulted, icache request won't be sent.
 730         memReq[tid] = NULL;
 731 
 732         // Send the fault to commit.  This thread will not do anything
 733         // until commit handles the fault.  The only other way it can
 734         // wake up is if a squash comes along and changes the PC.
 735         TheISA::PCState fetchPC = pc[tid];
 736 
 737         DPRINTF(Fetch, "[tid:%i] Translation faulted, building noop.\n", tid);
 738         // We will use a nop in ordier to carry the fault.
 739         DynInstPtr instruction = buildInst(tid, StaticInst::nopStaticInstPtr,
 740                                            NULL, fetchPC, fetchPC, false);
 741         instruction->setNotAnInst();
 742 
 743         instruction->setPredTarg(fetchPC);
 744         instruction->fault = fault;
 745         wroteToTimeBuffer = true;
 746 
 747         DPRINTF(Activity, "Activity this cycle.\n");
 748         cpu->activityThisCycle();
 749 
 750         fetchStatus[tid] = TrapPending;
 751 
 752         DPRINTF(Fetch, "[tid:%i] Blocked, need to handle the trap.\n", tid);
 753         DPRINTF(Fetch, "[tid:%i] fault (%s) detected @ PC %s.\n",
 754                 tid, fault->name(), pc[tid]);
 755     }
 756     _status = updateFetchStatus();
 757 }
```

When the TLB translation emits fault instead of successful translation, 
it should be handled based on the reason of the fault. 
When the fetchQeueue is already full or XXX (line 719-726),
instead of issuing cache access, it postpone the operation to later 
by scheduling the finishTranslationEvent. 
Note that the request packet received from the ITLB and fault structure 
is also included in the finishTranslationEvent to process it later. 


```cpp
140     /* Event to delay delivery of a fetch translation result in case of
141      * a fault and the nop to carry the fault cannot be generated
142      * immediately */
143     class FinishTranslationEvent : public Event
144     { 
145       private:
146         DefaultFetch<Impl> *fetch;
147         Fault fault;
148         RequestPtr req;
149       
150       public:
151         FinishTranslationEvent(DefaultFetch<Impl> *_fetch)
152             : fetch(_fetch), req(nullptr)
153         {}
154         
155         void setFault(Fault _fault)
156         {   
157             fault = _fault;
158         }
159         
160         void setReq(const RequestPtr &_req)
161         {   
162             req = _req;
163         }
164         
165         /** Process the delayed finish translation */
166         void process()
167         {   
168             assert(fetch->numInst < fetch->fetchWidth);
169             fetch->finishTranslation(fault, req);
170         }
171         
172         const char *description() const
173         {   
174             return "FullO3CPU FetchFinishTranslation";
175         }   
176       };
```
In detail, when the FinishTranslationEvent happens after the designated cycles passed,
it invokes the process function defined in the class. As shown in the above code line 166-170,
it calls finishTranslation with the passed fault and request again. 

For the other reason of faults, 
\TODO{explanation required for the rest of the faulting code}.
After the fetch stage handles the response from the ITLB, 
it should update the current status of the fetch stage by invoking the updateFetchStatus function.

```cpp
 841 template<class Impl>
 842 typename DefaultFetch<Impl>::FetchStatus
 843 DefaultFetch<Impl>::updateFetchStatus()
 844 {
 845     //Check Running
 846     list<ThreadID>::iterator threads = activeThreads->begin();
 847     list<ThreadID>::iterator end = activeThreads->end();
 848 
 849     while (threads != end) {
 850         ThreadID tid = *threads++;
 851 
 852         if (fetchStatus[tid] == Running ||
 853             fetchStatus[tid] == Squashing ||
 854             fetchStatus[tid] == IcacheAccessComplete) {
 855 
 856             if (_status == Inactive) {
 857                 DPRINTF(Activity, "[tid:%i] Activating stage.\n",tid);
 858 
 859                 if (fetchStatus[tid] == IcacheAccessComplete) {
 860                     DPRINTF(Activity, "[tid:%i] Activating fetch due to cache"
 861                             "completion\n",tid);
 862                 }
 863 
 864                 cpu->activateStage(O3CPU::FetchIdx);
 865             }
 866 
 867             return Active;
 868         }
 869     }
 870 
 871     // Stage is switching from active to inactive, notify CPU of it.
 872     if (_status == Active) {
 873         DPRINTF(Activity, "Deactivating stage.\n");
 874 
 875         cpu->deactivateStage(O3CPU::FetchIdx);
 876     }
 877 
 878     return Inactive;
 879 }
```

### processCacheCompletion: completing ICache access 
When the sendTimingReq is invoked through the icachePort, which means 
cache access request sent to the Instruction cache successfully, 
after few cycles elapsed, the O3CPU will be notified that the cache read completes.
The cache access completion is handled by the recvTimingResp of the IcachePort 
allocated for the O3CPU. 

```cpp
1676 template<class Impl>
1677 bool
1678 DefaultFetch<Impl>::IcachePort::recvTimingResp(PacketPtr pkt)
1679 {
1680     DPRINTF(O3CPU, "Fetch unit received timing\n");
1681     // We shouldn't ever get a cacheable block in Modified state
1682     assert(pkt->req->isUncacheable() ||
1683            !(pkt->cacheResponding() && !pkt->hasSharers()));
1684     fetch->processCacheCompletion(pkt);
1685 
1686     return true;
1687 }
```

When it receives the instructions from the cache, it invokes the 
processCacheCompletion function and ask this function to handle the 
response arrived from the cache. 


```cpp
 389 DefaultFetch<Impl>::processCacheCompletion(PacketPtr pkt)
 390 {
 391     ThreadID tid = cpu->contextToThread(pkt->req->contextId());
 392 
 393     DPRINTF(Fetch, "[tid:%i] Waking up from cache miss.\n", tid);
 394     assert(!cpu->switchedOut());
 395 
 396     // Only change the status if it's still waiting on the icache access
 397     // to return.
 398     if (fetchStatus[tid] != IcacheWaitResponse ||
 399         pkt->req != memReq[tid]) {
 400         ++fetchIcacheSquashes;
 401         delete pkt;
 402         return;
 403     }
 404 
 405     memcpy(fetchBuffer[tid], pkt->getConstPtr<uint8_t>(), fetchBufferSize);
 406     fetchBufferValid[tid] = true;
 407 
 408     // Wake up the CPU (if it went to sleep and was waiting on
 409     // this completion event).
 410     cpu->wakeCPU();
 411 
 412     DPRINTF(Activity, "[tid:%i] Activating fetch due to cache completion\n",
 413             tid);
 414 
 415     switchToActive();
 416 
 417     // Only switch to IcacheAccessComplete if we're not stalled as well.
 418     if (checkStall(tid)) {
 419         fetchStatus[tid] = Blocked;
 420     } else {
 421         fetchStatus[tid] = IcacheAccessComplete;
 422     }
 423 
 424     pkt->req->setAccessLatency();
 425     cpu->ppInstAccessComplete->notify(pkt);
 426     // Reset the mem req to NULL.
 427     delete pkt;
 428     memReq[tid] = NULL;
 429 }
```

When the instructions from the cache arrives, it could be the case where 
the misspeculation had initiated the cache access. 
In that case, it should drop the cache access by deleting the response packet.
In other cases, the read instructions should be copied from the packet to the 
**fetchBuffer** containing the fetched instructions (line 405-406). 
When the current tid is stalled because of some events (we will cover which condition
makes the thread to be stalled), it should be blocked until the stall is resolved.
If there is no stall, then the fetchStatus can be changed to **IcacheAccessComplete**,
which means the thread can finish the fetch stage.
Now let's go back to the fetch function again!

## Revisiting fetch stage to handle the instructions fetched from the cache

### Fetch tick happens every processor tick
One important thing to note is that Fetch stage is always executed at every clock cycle.
However, based on the current status of the processor and other components such as 
TLB and cache, fetch stage cannot produce meaningful progress and should wait 
until the other component finish their operations. Although modern processors 
have multiple cores to execute, but if the all cores are waiting the cache accesses, 
no other hardware thread cannot execute the fetch stage. The **getFetchingThread**
function checks the status of the all hardware threads and returns thread if there is one
that can execute the fetch stage. 

```cpp
1156 template<class Impl>
1157 void
1158 DefaultFetch<Impl>::fetch(bool &status_change)
1159 {
1160     //////////////////////////////////////////
1161     // Start actual fetch
1162     //////////////////////////////////////////
1163     ThreadID tid = getFetchingThread();
1164 
1165     assert(!cpu->switchedOut());
1166 
1167     if (tid == InvalidThreadID) {
1168         // Breaks looping condition in tick()
1169         threadFetched = numFetchingThreads;
1170 
1171         if (numThreads == 1) {  // @todo Per-thread stats
1172             profileStall(0);
1173         }
1174 
1175         return;
1176     }
```

As shown in the above code, when there is no available hardware thread to execute fetch stage,
getFetchingThread returns InvalidThreadID, and no thread can produce progress at that clock cycle.
Only the case where the getFetchingThread returns an available thread is the thread is in 
one of the three fetchStatus: Running, IcacheAccessComplete, or Idle. 


```
   1000: system.cpu.fetch: Running stage.
   1000: system.cpu.fetch: Attempting to fetch from [tid:0]
   1000: system.cpu.fetch: [tid:0] Attempting to translate and read instruction, starting at PC (0x7ffff8000090=>0x7ffff8000098).(0=>1).
   1000: system.cpu.fetch: [tid:0] Fetching cache line 0x7ffff8000080 for addr 0x7ffff8000090
   1000: system.cpu.fetch: Fetch: Doing instruction read.
   1000: system.cpu.fetch: [tid:0] Doing Icache access.
   1500: system.cpu.fetch: Running stage.
   1500: system.cpu.fetch: There are no more threads available to fetch from.
   1500: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   2000: system.cpu.fetch: Running stage.
   2000: system.cpu.fetch: There are no more threads available to fetch from.
   2000: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   2500: system.cpu.fetch: Running stage.
   2500: system.cpu.fetch: There are no more threads available to fetch from.
   2500: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   3000: system.cpu.fetch: Running stage.
   3000: system.cpu.fetch: There are no more threads available to fetch from.
   3000: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   3500: system.cpu.fetch: Running stage.
   3500: system.cpu.fetch: There are no more threads available to fetch from.
   3500: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   4000: system.cpu.fetch: Running stage.
   4000: system.cpu.fetch: There are no more threads available to fetch from.
   4000: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   4500: system.cpu.fetch: Running stage.
   4500: system.cpu.fetch: There are no more threads available to fetch from.
   4500: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   5000: system.cpu.fetch: Running stage.
   5000: system.cpu.fetch: There are no more threads available to fetch from.
   5000: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
   5500: system.cpu.fetch: Running stage.
   5500: system.cpu.fetch: There are no more threads available to fetch from.
   5500: system.cpu.fetch: [tid:0] Fetch is waiting cache response!
  78000: system.cpu.fetch: [tid:0] Waking up from cache miss.
  78001: system.cpu.fetch: [tid:0] Waking up from cache miss.
  78500: system.cpu.fetch: Running stage.
  78500: system.cpu.fetch: Attempting to fetch from [tid:0]
  78500: system.cpu.fetch: [tid:0] Icache miss is complete.
```

In our current system, because we only have one hardware thread, 
while it waits for the ICache miss to be resolved, it cannot execute fetch stage
to produce further progress. The described behavior of the fetch stage is described 
in the above log. After the thread first fetches the instructions at cycle 1000,
it cannot produce any progress until the ICache miss is resolved at cycle 78000. 
After the ICache miss is resolved (after 78500 cycle), it can finally produce progress from the fetch stage.
Remember that when a missed ICache is resolved by the processCacheCompletion function, 
it changes the fetchStatus of the thread from IcacheWaitResponse to **IcacheAccessComplete**.
Therefore, when the fetch stage is executed once again, the undiscovered path will be executed. 

```cpp
1188     // If returning from the delay of a cache miss, then update the status
1189     // to running, otherwise do the cache access.  Possibly move this up
1190     // to tick() function.
1191     if (fetchStatus[tid] == IcacheAccessComplete) {
1192         DPRINTF(Fetch, "[tid:%i] Icache miss is complete.\n", tid);
1193 
1194         fetchStatus[tid] = Running;
1195         status_change = true;
1196     } else if (fetchStatus[tid] == Running) {
```

Compared to the initial fetch execution that initiated the ITLB and ICache accesses, 
because the fetchStatus has been changed to IcacheAccessComplete,
the fetch stage can execute the rest of the fetch function at this moment. 
Let's take a look at the rest of the fetch function in detail. 

### fetchBuffer contains actual instructions for a particular hardware thread
```cpp
1235     //when a requested instruction cache block is arrived(IcacheAccessComplete)
1236     ++fetchCycles;
1237 
1238     TheISA::PCState nextPC = thisPC;
1239 
1240     StaticInstPtr staticInst = NULL;
1241     StaticInstPtr curMacroop = macroop[tid];
1242 
1243     // If the read of the first instruction was successful, then grab the
1244     // instructions from the rest of the cache line and put them into the
1245     // queue heading to decode.
1246 
1247     DPRINTF(Fetch, "[tid:%i] Adding instructions to queue to "
1248             "decode.\n", tid);
1249 
1250     // Need to keep track of whether or not a predicted branch
1251     // ended this fetch block.
1252     bool predictedBranch = false;
1253 
1254     // Need to halt fetch if quiesce instruction detected
1255     bool quiesce = false;
1256 
1257     TheISA::MachInst *cacheInsts =
1258         reinterpret_cast<TheISA::MachInst *>(fetchBuffer[tid]);
1259
1260     const unsigned numInsts = fetchBufferSize / instSize;
1261     unsigned blkOffset = (fetchAddr - fetchBufferPC[tid]) / instSize;
```

Remember that the fetchBuffer[tid] contains the actual instructions read from
the ICache. Note that cacheInsts variable which is the TheISA::MachInst * type 
references the instruction buffer, fetchBuffer[tid].
This variable is passed to the decoder to pass the instruction stream read from the ICache. 
Also, the TheISA::MachInst is a uint64_t in the x86 architecture (TheISA will be changes to the X86 namespace). 
Because X86 architecture adopts variable instruction length, it approximately 
set the instruction length as 8bytes and calculate the number of instructions 
in the instruction stream fetched from the ICache. 
Note that the numInsts is approximated as fetchBufferSize / instSize.

### The main fetchloop processing instructions
```cpp
1263     // Loop through instruction memory from the cache.
1264     // Keep issuing while fetchWidth is available and branch is not
1265     // predicted taken
1266     while (numInst < fetchWidth && fetchQueue[tid].size() < fetchQueueSize
1267            && !predictedBranch && !quiesce) {
```

The while loop (line 1266-1267) is the main body of processing instructions 
stored in the fetchBuffer. Be careful not to confuse numInst with numInsts.
numInst means the number of instructions fetched at this cycle, and numInsts means 
the number of instructions that can possibly reside in the fetchBuffer. 
Also, fetchQueue is the CPP standard deque managing DynInstPtr which is the pointer 
of one macroop instruction. Therefore, the loop checks first whether the number of 
fetched instructions at this cycle exceed the deisgnated fetchWidth and examine 
whether the fetchQueue is overflowed, which means too many instructions have been fetched 
from the instruction cache. Because the instruction length can vary but the capacity 
of fetchQueue is limited, sometimes depending on which instructions actually reside
in the fetched instruction cache, it cannot process all instructions at that cycle. 
Based on the fact that it checks if the fetchQueue is overflowed at every iteration, 
we can assume that the loop insert instruction to the fetchQueue. We will take a look at 
the details soon!
Also it checks the type of the previous instruction handled by the loop, 
whether it is predictedBranch or quiesce. If the previous instruction turns out to 
one of these type of instruction, then the loop should not process the instruction
in the fetchBuffer further and stop. 

### Decoder
```cpp
1268         // We need to process more memory if we aren't going to get a
1269         // StaticInst from the rom, the current macroop, or what's already
1270         // in the decoder.
1271         bool needMem = !inRom && !curMacroop &&
1272             !decoder[tid]->instReady();
1273         fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1274         Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1275 
1276         if (needMem) {
1277             // If buffer is no longer valid or fetchAddr has moved to point
1278             // to the next cache block then start fetch from icache.
1279             if (!fetchBufferValid[tid] ||
1280                 fetchBufferBlockPC != fetchBufferPC[tid])
1281                 break;
1282 
1283             if (blkOffset >= numInsts) {
1284                 // We need to process more memory, but we've run out of the
1285                 // current block.
1286                 break;
1287             }
1288 
1289             decoder[tid]->moreBytes(thisPC, fetchAddr, cacheInsts[blkOffset]);
1290 
1291             if (decoder[tid]->needMoreBytes()) {
1292                 blkOffset++;
1293                 fetchAddr += instSize;
1294                 pcOffset += instSize;
1295             }
1296         }
```

After the all conditions are met, each iteration of the loop processes the instruction 
one by one. For the first execution of the fetch stage, the inRom and curMacroop are set 
as false and NULL respectively. Also, when the decoder object embedded in the fetch stage 
is initialized, the instDone variable of the decoder is set as false, which will be returned 
as the result of instReady function of the decoder. 
Therefore, the needMem should be set for the initial execution. 
When the needMem flag is set, which means \TODO{XXX},
it invokes moreBytes function of the decoder to decode the instruction. 



```cpp
306     //Use this to give data to the decoder. This should be used
307     //when there is control flow.
308     void moreBytes(const PCState &pc, Addr fetchPC, MachInst data)
309     {
310         DPRINTF(Decoder, "Getting more bytes.\n");
311         basePC = fetchPC;
312         offset = (fetchPC >= pc.instAddr()) ? 0 : pc.instAddr() - fetchPC;
313         fetchChunk = letoh(data);
314         outOfBytes = false;
315         process();
316     }
```


```cpp
 74 Decoder::process()
 75 {
 76     //This function drives the decoder state machine.
 77 
 78     //Some sanity checks. You shouldn't try to process more bytes if
 79     //there aren't any, and you shouldn't overwrite an already
 80     //decoder ExtMachInst.
 81     assert(!outOfBytes);
 82     assert(!instDone);
 83 
 84     if (state == ResetState)
 85         state = doResetState();
 86     if (state == FromCacheState) {
 87         state = doFromCacheState();
 88     } else {
 89         instBytes->chunks.push_back(fetchChunk);
 90     }
 91 
 92     //While there's still something to do...
 93     while (!instDone && !outOfBytes) {
 94         uint8_t nextByte = getNextByte();
 95         switch (state) {
 96           case PrefixState:
 97             state = doPrefixState(nextByte);
 98             break;
 99           case Vex2Of2State:
100             state = doVex2Of2State(nextByte);
101             break;
102           case Vex2Of3State:
103             state = doVex2Of3State(nextByte);
104             break;
105           case Vex3Of3State:
106             state = doVex3Of3State(nextByte);
107             break;
108           case VexOpcodeState:
109             state = doVexOpcodeState(nextByte);
110             break;
111           case OneByteOpcodeState:
112             state = doOneByteOpcodeState(nextByte);
113             break;
114           case TwoByteOpcodeState:
115             state = doTwoByteOpcodeState(nextByte);
116             break;
117           case ThreeByte0F38OpcodeState:
118             state = doThreeByte0F38OpcodeState(nextByte);
119             break;
120           case ThreeByte0F3AOpcodeState:
121             state = doThreeByte0F3AOpcodeState(nextByte);
122             break;
123           case ModRMState:
124             state = doModRMState(nextByte);
125             break;
126           case SIBState:
127             state = doSIBState(nextByte);
128             break;
129           case DisplacementState:
130             state = doDisplacementState();
131             break;
132           case ImmediateState:
133             state = doImmediateState();
134             break;
135           case ErrorState:
136             panic("Went to the error state in the decoder.\n");
137           default:
138             panic("Unrecognized state! %d\n", state);
139         }
140     }
141 }
```
Based on the instruction format, different doXXX function will be invoked to parse
the macroop instruction. First of all, it invokes doResetState for every macroop to 
initialize the variables representing the parsed instruction. Also it sets the 
origPC field as the PC address of the macroop instruction,. 
After the initialization, based on the instruction format, it will invoke 
different parsing code. Based on the n-1 byte(s) of the instruction,
next n(+1) bytes of the instruction's format will be determined. 
Therefore, by parsing each byte one by one, different format of the instruction
can be fully decoded by the above process function.
During the parsing, it invokes consumeByte(s) function when a particular 
part of the instruction could be successfully decoded. 
The consumeByte function increases the offset variable of the decoder to present 
the length of the currently being parsed macroop. 


### The second loop to process each instruction
The most important variable in the second loop is **curMacroop**. 
As implied by its name, this variable contains current macroop of the selected thread,
StaticInstPtr.

```cpp
1378         } while ((curMacroop || decoder[tid]->instReady()) &&
1379                  numInst < fetchWidth &&
1380                  fetchQueue[tid].size() < fetchQueueSize);
```

As shown in the above code, the second loop continues until the curMacroop is not set as NULL
or decoder finish to decode the instruction. 
Let's take a look at the details of the second loop. 

```cpp
1298         // Extract as many instructions and/or microops as we can from
1299         // the memory we've processed so far.
1300         do {
1301             if (!(curMacroop || inRom)) {
1302                 if (decoder[tid]->instReady()) {
1303                     staticInst = decoder[tid]->decode(thisPC);
1304 
1305                     // Increment stat of fetched instructions.
1306                     ++fetchedInsts;
1307 
1308                     if (staticInst->isMacroop()) {
1309                         curMacroop = staticInst;
1310                     } else {
1311                         pcOffset = 0;
1312                     }
1313                 } else {
1314                     // We need more bytes for this instruction so blkOffset and
1315                     // pcOffset will be updated
1316                     break;
1317                 }
1318             }
```

Note that we are currently doesn't have a curMacroop and not executing the ROM code (microops).
Also, decoder[tid]->instReady is now true because the moreBytes function successfully decoded the 
macroop instruction. Therefore, it will invoke the decode function.
UpdateNPC should be expalined!!!


```cpp
1319             // Whether we're moving to a new macroop because we're at the
1320             // end of the current one, or the branch predictor incorrectly
1321             // thinks we are...
1322             bool newMacro = false;
1323             if (curMacroop || inRom) {
1324                 if (inRom) {
1325                     staticInst = cpu->microcodeRom.fetchMicroop(
1326                             thisPC.microPC(), curMacroop);
1327                 } else {
1328                     staticInst = curMacroop->fetchMicroop(thisPC.microPC());
1329                 }
1330                 newMacro |= staticInst->isLastMicroop();
1331             }
1332 
1333             DynInstPtr instruction =
1334                 buildInst(tid, staticInst, curMacroop,
1335                           thisPC, nextPC, true);
1336 
1337             ppFetch->notify(instruction);
1338             numInst++;
1339 
1340 #if TRACING_ON
1341             if (DTRACE(O3PipeView)) {
1342                 instruction->fetchTick = curTick();
1343             }
1344 #endif
1345 
1346             nextPC = thisPC;
1347 
1348             // If we're branching after this instruction, quit fetching
1349             // from the same block.
1350             predictedBranch |= thisPC.branching();
1351             predictedBranch |=
1352                 lookupAndUpdateNextPC(instruction, nextPC);
1353             if (predictedBranch) {
1354                 DPRINTF(Fetch, "Branch detected with PC = %s\n", thisPC);
1355             }
1356 
1357             newMacro |= thisPC.instAddr() != nextPC.instAddr();
1358 
1359             // Move to the next instruction, unless we have a branch.
1360             thisPC = nextPC;
1361             inRom = isRomMicroPC(thisPC.microPC());
1362 
1363             if (newMacro) {
1364                 fetchAddr = thisPC.instAddr() & BaseCPU::PCMask;
1365                 blkOffset = (fetchAddr - fetchBufferPC[tid]) / instSize;
1366                 pcOffset = 0;
1367                 curMacroop = NULL;
1368             }
1369 
1370             if (instruction->isQuiesce()) {
1371                 DPRINTF(Fetch,
1372                         "Quiesce instruction encountered, halting fetch!\n");
1373                 fetchStatus[tid] = QuiescePending;
1374                 status_change = true;
1375                 quiesce = true;
1376                 break;
1377             }
1378         } while ((curMacroop || decoder[tid]->instReady()) &&
1379                  numInst < fetchWidth &&
1380                  fetchQueue[tid].size() < fetchQueueSize);
1381 
1382         // Re-evaluate whether the next instruction to fetch is in micro-op ROM
1383         // or not.
1384         inRom = isRomMicroPC(thisPC.microPC());
1385     }
1386 
1387     if (predictedBranch) {
1388         DPRINTF(Fetch, "[tid:%i] Done fetching, predicted branch "
1389                 "instruction encountered.\n", tid);
1390     } else if (numInst >= fetchWidth) {
1391         DPRINTF(Fetch, "[tid:%i] Done fetching, reached fetch bandwidth "
1392                 "for this cycle.\n", tid);
1393     } else if (blkOffset >= fetchBufferSize) {
1394         DPRINTF(Fetch, "[tid:%i] Done fetching, reached the end of the"
1395                 "fetch buffer.\n", tid);
1396     }
1397 
1398     macroop[tid] = curMacroop;
1399     fetchOffset[tid] = pcOffset;
1400 
1401     if (numInst > 0) {
1402         wroteToTimeBuffer = true;
1403     }
1404 
1405     pc[tid] = thisPC;
1406 
1407     // pipeline a fetch if we're crossing a fetch buffer boundary and not in
1408     // a state that would preclude fetching
1409     fetchAddr = (thisPC.instAddr() + pcOffset) & BaseCPU::PCMask;
1410     Addr fetchBufferBlockPC = fetchBufferAlignPC(fetchAddr);
1411     issuePipelinedIfetch[tid] = fetchBufferBlockPC != fetchBufferPC[tid] &&
1412         fetchStatus[tid] != IcacheWaitResponse &&
1413         fetchStatus[tid] != ItlbWait &&
1414         fetchStatus[tid] != IcacheWaitRetry &&
1415         fetchStatus[tid] != QuiescePending &&
1416         !curMacroop;
1417 }
```




### buildInst: parsing instruction from the retrieved Instruction cache 
```cpp
1102 template<class Impl>
1103 typename Impl::DynInstPtr
1104 DefaultFetch<Impl>::buildInst(ThreadID tid, StaticInstPtr staticInst,
1105                               StaticInstPtr curMacroop, TheISA::PCState thisPC,
1106                               TheISA::PCState nextPC, bool trace)
1107 {
1108     // Get a sequence number.
1109     InstSeqNum seq = cpu->getAndIncrementInstSeq();
1110 
1111     // Create a new DynInst from the instruction fetched.
1112     DynInstPtr instruction =
1113         new DynInst(staticInst, curMacroop, thisPC, nextPC, seq, cpu);
1114     instruction->setTid(tid);
1115 
1116     instruction->setASID(tid);
1117 
1118     instruction->setThreadState(cpu->thread[tid]);
1119 
1120     DPRINTF(Fetch, "[tid:%i] Instruction PC %#x (%d) created "
1121             "[sn:%lli].\n", tid, thisPC.instAddr(),
1122             thisPC.microPC(), seq);
1123 
1124     DPRINTF(Fetch, "[tid:%i] Instruction is: %s\n", tid,
1125             instruction->staticInst->
1126             disassemble(thisPC.instAddr()));
1127 
1128 #if TRACING_ON
1129     if (trace) {
1130         instruction->traceData =
1131             cpu->getTracer()->getInstRecord(curTick(), cpu->tcBase(tid),
1132                     instruction->staticInst, thisPC, curMacroop);
1133     }
1134 #else
1135     instruction->traceData = NULL;
1136 #endif
1137 
1138     // Add instruction to the CPU's list of instructions.
1139     instruction->setInstListIt(cpu->addInst(instruction));
1140 
1141     // Write the instruction to the first slot in the queue
1142     // that heads to decode.
1143     assert(numInst < fetchWidth);
1144     fetchQueue[tid].push_back(instruction);
1145     assert(fetchQueue[tid].size() <= fetchQueueSize);
1146     DPRINTF(Fetch, "[tid:%i] Fetch queue entry created (%i/%i).\n",
1147             tid, fetchQueue[tid].size(), fetchQueueSize);
1148     //toDecode->insts[toDecode->size++] = instruction;
1149 
1150     // Keep track of if we can take an interrupt at this boundary
1151     delayedCommit[tid] = instruction->isDelayedCommit();
1152 
1153     return instruction;
1154 }
```



###
```cpp
 556 template <class Impl>
 557 bool
 558 DefaultFetch<Impl>::lookupAndUpdateNextPC(
 559         const DynInstPtr &inst, TheISA::PCState &nextPC)
 560 {
 561     // Do branch prediction check here.
 562     // A bit of a misnomer...next_PC is actually the current PC until
 563     // this function updates it.
 564     bool predict_taken;
 565 
 566     if (!inst->isControl()) {
 567         TheISA::advancePC(nextPC, inst->staticInst);
 568         inst->setPredTarg(nextPC);
 569         inst->setPredTaken(false);
 570         return false;
 571     }
 572 
 573     ThreadID tid = inst->threadNumber;
 574     predict_taken = branchPred->predict(inst->staticInst, inst->seqNum,
 575                                         nextPC, tid);
 576 
 577     if (predict_taken) {
 578         DPRINTF(Fetch, "[tid:%i] [sn:%llu] Branch at PC %#x "
 579                 "predicted to be taken to %s\n",
 580                 tid, inst->seqNum, inst->pcState().instAddr(), nextPC);
 581     } else {
 582         DPRINTF(Fetch, "[tid:%i] [sn:%llu] Branch at PC %#x "
 583                 "predicted to be not taken\n",
 584                 tid, inst->seqNum, inst->pcState().instAddr());
 585     }
 586 
 587     DPRINTF(Fetch, "[tid:%i] [sn:%llu] Branch at PC %#x "
 588             "predicted to go to %s\n",
 589             tid, inst->seqNum, inst->pcState().instAddr(), nextPC);
 590     inst->setPredTarg(nextPC);
 591     inst->setPredTaken(predict_taken);
 592 
 593     ++fetchedBranches;
 594 
 595     if (predict_taken) {
 596         ++predictedBranches;
 597     }
 598 
 599     return predict_taken;
 600 }
```
